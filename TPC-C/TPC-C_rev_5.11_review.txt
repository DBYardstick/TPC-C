

.) This document is to record important facts about the benchmark, and to discuss
variations and options allowed by the TPC-C benchmark specification.

.) Terms used:

SUT: System Under Run.

TPC-C Aplication: The application that performs transactions in conformance with
					the TPC-C Spec; eg. our application.

RT: Response Time

TM: Transaction Monitor, or Transaction Processing Monitor

.) Section 0.3:

.) TYPO: repeats the phrase 'is an accepted'.

This section allows new methodologies and approaches for the implementation so
long as the rules are adhered to. So I guess trying TPC-C implementation in
JavaScript, for the advantages I am seeking, can be considered a new methodology.

Section 1.1 (Logical Design):

A company has various warehouses. Each warehouse holds stock of 100,000 items
sold by the company. Each warehouse serves 10 districts, and each district
serves 3000 customers.

Customers call to place orders or check the status of the orders. Each order, on
average consists of 10 items (a.k.a line items). One percent of all line items
are for an item that is out of stock at the local warehous, and has to be
supplied by a remote warehouse.

The system is also used to accepts customers' payments, check stock level, and
process orders for delivery.

Section 1.3 (DB layout):

.) "N unique IDs" mean that column/attribute should be capable of holding a
minimum of N unique identifiers, using whatever data type suited for the
purpose; eg. strings, binary data, packed decimal, etc.

.) "variable text, size N" means the column/sttribute should be able to hold a
string of **maximum** length N.

If fixed-length data type is used here instead, then if the string being stored
is smaller than N, then the string should be stored with padding.

DISCUSSION: I think this clause mentioning fixed data type is to allow for DBMS'
that don't have variable-length string data types. I think it can be safely
ignored, as Postgres has text and varchar data types. But if fixed-length data
types (say, char) provides improved performance, then the benchmark allows it.

.) "fixed text, size N" means the column should be capable of holding character
strings of length exacly N.

.) "date and time" means a data type that holds date and time. The data type
should be capable of holding values between '1st January 1900' and
'31st December 2100'.

The time component must be capable of representing the range of time values from
00:00:00 to 23:59:59 with a resolution of at least one second.

Date and Time must be implemented using data types that are defined by the DBMS
for that use.

.) "numeric(m [,n])" means an **unsigned** numeric with at least m total digits
and n of those are to the right of the decimal point. The columns/attributes
that are used to store monetary values (W_YTD, I_PRICE, etc.) must use the data
type that is defined as an **exact numeric data type**, or should satisfy ANSI
SQL definition of being an exact numeric representation.

DISCUSSION: I think the primary purpose of this data type is to hold monitary
values, and the database specific implementations are allowed (e.g. money data
type in Postgres).

TODO: Investigate what an **exact numeric data type** means and if Postgres has
any data type that satisfies the definition, and is also faster than the
'numeric' data type as implemented in Postgres.

.) "signed numeric(m,n)" implies same definitions as 'numeric(m,n)' above,
except that this data type can also store negative values.

.) TPC-C spec allows for 'signed numeric' can be used anywhere the 'numeric'
data type is defined.

Consider this comment: "For each table, the following list of attributes can be
implemented in any order, using any physical representation available from the
tested system". It specifically allows for reordering of columns in the table.
So, the TODO item for when the benchmark is implemented successfully, is to
measure the difference between the spec-provided layout and the often cited myth
that the fixed-length data types should be grouped towards the beginning of the
column list.

"Note: The TPC-C application does not have to be capable of utilizing the
increased range of C_ID values beyond 6,000."

.) Does the clause 1.4.2 prohibit us from implementing one TPC-C transaction as a
single CTE query comprising of multiple operations? If yes, then some of the other
TPC-C applications (term used in spec.) seem to be violating this by implementing
the transaction in plpgsql functions.

Clause 2.1.7 mentions the stored procedures, triggers and foreign keys to be
a part of the application program/TPC-C application. Which seems to imply that
it is acceptable for the transaction profiles to be written purely in stored
procedures/functions.


.) I think clause 1.4.6 precludes "asynchronous" streaming replication, but allows for
"synchronous" streaming replication.

Correction: The comment immediately after 1.4.6 seems to imply that "async"
replication is fine, too. We'll see when we cover section 3 about ACID compliance.


.) Partitioning

Clauses 1.4.4 and 1.5.1 combined imply that hoirizontal partitioning is allowed
as long as the operation across the partitions is done in a transaction.


.) NURand: non-uniform random, used **only for generating** customer numbers, customer last names,
and item numbers,


NURand (A, x, y) = (((random (0, A) | random (x, y)) + C) % (y - x + 1)) + x

for C_LAST, the range is [0 .. 999] and A = 255
for C_ID, the range is [1 .. 3000] and A = 1023
for OL_I_ID, the range is [1 .. 100000] and A = 8191


.) Clause 2.1.8 requires the terminal to be at least 24 x 80 characters in size,
and that it should be a dumb terminal, meaning it doesn't have any knowledge of
the application, except how to display the application's interface.

Clause 2.2.1.2 allows for reordering/repositioning of the fields, not that I think
we will need to do that.

If a screen layout (other than the ones listed in clauses 2.4.3.1, 2.5.3.1,
2.6.3.1, 2.7.3.1, and 2.8.3.1) is used, it must be included in the
'Full Disclosure Report'.

2.2.1.4 Allows for the application to not display fields that are unused for a
screen, like empty fields for Order-line-items in New Order screen.

2.2.1.5 requires that all editable fields on the screen be cleared before each
transaction, even if same transaction is being used as the previous one.

2.2.1.6/7 make it clear that a menu be used which allows the user to choose the
transaction to be performed next. The menu should contain the name of the
transactions, and action to be taken by the user to choose a transaction.

2.2.1.8 There shouldn't be any display components/fields other than required by
the specification. If there are any, they should be disclosed with an explanation.

{{{

IMPORTANT: RE-REVIEW with someone/auditor:
2.2.2.4.1 requires that the characters are echoed back as they are entered by the
operator in the fields. The comment afterwards allows that if the terminal is
implemeted in a browser, on a PC etc. then this echo-test is not required.

Since this whole 2.2.2 section mandates a RTE that the terminal be a fully
functional one, where someone can actually switch back and forth between fields,
enter text one character at a time, etc., I am not going to implement it until
the end (after the database interaction layer is finished). I currenlty don't
feel confident enough with 'blessed' library to implement a complete functional
terminal.

}}}

## TP Monitor (Transaction [Processing] Monitor)

Clause 2.3.5 applies if some kind of connection pooler or transaction manager is
used inside SUT. Since I, at least initially, intend to use a connection pooler
inside the NodeJS application (most likely the connection pool offered by
node-postgres), I don't think I need to worry about this component.

Even if an external software, like pgbouncer, is used as a TP Monitor the TPC-C
application doesn't need to be modified for it

For an actual TPC-C run, the auditor might insist on not using the
in-application connection pooler, becauase in a real-world setup, the terminals
spread around geographically cannot be made to use such a technology.

Initially, since Postgres is considered capable of handling between 300-400
connections under OLTP workloads, it may not even be necessary to use a
TPMonitor, and make the connections directly to the database. This is explicitly
allowed by 'Comment 3' under clause 2.3.5.

Clause 2.3.6 requires that for interactive transactions, in case of an error,
some kind of error message be reported the terminal. And in case of
non-interactive transactions, the error be logged in log files.

## New Order Transaction Profile

.) Warehouse associated with a terminal is fixed.

.) All New Order transactions should use freshly generated data before each run.

TODO
====

1. Clause 2.1.6.1 requires certain characteristics of the runtime constant C and
		I currently don't understand how those characteristics can be enforced.
		Also, I don't see where C_LAST is generated during the measurement runs,
		although admittedly, I have studied only the New Order transaction profile
		as of now.
